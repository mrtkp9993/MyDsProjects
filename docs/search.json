[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Murat Koptur",
    "section": "",
    "text": "I’m a mathematician and data scientist from Turkey. I have experience in developing and building end-to-end data science solutions. My interests are data science, numerical analysis, dynamical systems and chaos, and mathematical/statistical modeling.\nWhen not playing with data, I’m enjoying spending time playing music and working on digital art paintings."
  },
  {
    "objectID": "AnomalyOcsvm/Analysis.html",
    "href": "AnomalyOcsvm/Analysis.html",
    "title": "Unsupervised Anomaly Detection with One-Class SVM",
    "section": "",
    "text": "Introduction\nAnomaly detection (outlier detection, novelty detection) is the identification of rare observations that differ substantially from the vast majority of the data \\(^4\\).\nI would like to point out an important distinction \\(^3\\):\n\nOutlier detection: The training data contains outliers. Estimators try to fit the regions where the training data is the most concentrated.\nNovelty detection: The training data does not contain outliers. Estimators try to detect whether a new observation is an outlier.\n\nIn short, SVMs separates two classes using a hyperplane with the largest possible margin. On other side, One-Class SVMs try to identify smallest hypersphere which contains most of the data points\\(^4\\).\n\n\n\nSource: \\(^5\\)\n\n\n\n\nExample\nDataset was downloaded from ODDS \\(^{1,2}\\). The original dataset contains labels but we’ll not use them.\n\ndata = arff.loadarff('seismic-bumps.arff')\ndf = pd.DataFrame(data[0])\n\nfor col in df:\n    if isinstance(df[col][0], bytes):\n        df[col] = df[col].str.decode(\"utf8\")\n\nMarkdown(tabulate(\n  df.head(), \n  headers=df.columns\n))\n\n\n\n\n\nseismic\nseismoacoustic\nshift\ngenergy\ngpuls\ngdenergy\ngdpuls\nghazard\nnbumps\nnbumps2\nnbumps3\nnbumps4\nnbumps5\nnbumps6\nnbumps7\nnbumps89\nenergy\nmaxenergy\nclass\n\n\n\n\n0\na\na\nN\n15180\n48\n-72\n-72\na\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\na\na\nN\n14720\n33\n-70\n-79\na\n1\n0\n1\n0\n0\n0\n0\n0\n2000\n2000\n0\n\n\n2\na\na\nN\n8050\n30\n-81\n-78\na\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\na\na\nN\n28820\n171\n-23\n40\na\n1\n0\n1\n0\n0\n0\n0\n0\n3000\n3000\n0\n\n\n4\na\na\nN\n12640\n57\n-63\n-52\na\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\nLet’s drop categorical columns and class column:\n\ndf = df.loc[:, ~df.columns.isin(['seismic', 'seismoacoustic', 'shift', 'ghazard', 'class'])]\n\nMarkdown(tabulate(\n  df.head(), \n  headers=df.columns\n))\n\n\n\n\n\ngenergy\ngpuls\ngdenergy\ngdpuls\nnbumps\nnbumps2\nnbumps3\nnbumps4\nnbumps5\nnbumps6\nnbumps7\nnbumps89\nenergy\nmaxenergy\n\n\n\n\n0\n15180\n48\n-72\n-72\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n14720\n33\n-70\n-79\n1\n0\n1\n0\n0\n0\n0\n0\n2000\n2000\n\n\n2\n8050\n30\n-81\n-78\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n28820\n171\n-23\n40\n1\n0\n1\n0\n0\n0\n0\n0\n3000\n3000\n\n\n4\n12640\n57\n-63\n-52\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\nSplit data to train and test sets:\n\nX_train, X_test = train_test_split(df, test_size = 0.2)\n\nSVM tries to maximize distance between the hyperplane and the support vectors. If some features have very big values, they will dominate the other features. So it is important to rescale data while using distance based methods:\n\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nMarkdown(tabulate(\n  X_train_scaled[:5], \n  headers=df.columns,\n))\n\n\nScaled Train set \n\n\ngenergy\ngpuls\ngdenergy\ngdpuls\nnbumps\nnbumps2\nnbumps3\nnbumps4\nnbumps5\nnbumps6\nnbumps7\nnbumps89\nenergy\nmaxenergy\n\n\n\n\n0.0322751\n0.255757\n0.191648\n0.142398\n0.222222\n0\n0.4\n0\n0\n0\n0\n0\n0.0248756\n0.015\n\n\n0.957234\n0.888397\n0.0917226\n0.130621\n0.222222\n0\n0.4\n0\n0\n0\n0\n0\n0.00995025\n0.0075\n\n\n0.0172349\n0.116253\n0.102163\n0.126338\n0.111111\n0\n0.2\n0\n0\n0\n0\n0\n0.0199005\n0.02\n\n\n0.0106506\n0.131311\n0.128262\n0.1606\n0.111111\n0\n0.2\n0\n0\n0\n0\n0\n0.00248756\n0.0025\n\n\n0.0139838\n0.130425\n0.0887397\n0.0974304\n0.111111\n0.125\n0\n0\n0\n0\n0\n0\n0.000497512\n0.0005\n\n\n\n\n\n\nMarkdown(tabulate(\n  X_test_scaled[:5], \n  headers=df.columns,\n))\n\n\nScaled Test set \n\n\ngenergy\ngpuls\ngdenergy\ngdpuls\nnbumps\nnbumps2\nnbumps3\nnbumps4\nnbumps5\nnbumps6\nnbumps7\nnbumps89\nenergy\nmaxenergy\n\n\n\n\n0.0119256\n0.0225864\n0.0671141\n0.0310493\n0.555556\n0.25\n0.4\n0.333333\n0\n0\n0\n0\n0.0629353\n0.05\n\n\n0.0613673\n0.463685\n0.0589113\n0.107066\n0.444444\n0.25\n0.4\n0\n0\n0\n0\n0\n0.0126866\n0.0075\n\n\n0.00139792\n0.00752879\n0.0059657\n0.0182013\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0.0128681\n0.0396368\n0.0268456\n0.0171306\n0.222222\n0.125\n0.2\n0\n0\n0\n0\n0\n0.00945274\n0.0075\n\n\n0.0143845\n0.144818\n0.132737\n0.116702\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\nApply T-SNE for 2-d visualization:\n\nt_sne = TSNE(n_components=2, \n             learning_rate = 'auto',\n             init='pca',\n             random_state=1234)\n             \nX_train_viz = t_sne.fit_transform(X_train_scaled)\nX_test_viz = t_sne.fit_transform(X_test_scaled)\n\n\npx.scatter(x=X_train_viz[:,0], y=X_train_viz[:,1], title=\"Train set\")\n\n\n                                                \n\n\n\npx.scatter(x=X_test_viz[:,0], y=X_test_viz[:,1], title=\"Test set\")\n\n\n                                                \n\n\nLet’s train and predict:\n\n# We assume that the proportion of outliers in the data set is 0.15\nclf = OCSVM(contamination=0.15)\nclf.fit(X_train_scaled)\n\nX_train_pred = clf.labels_  # binary labels (0: inliers, 1: outliers)\nX_train_scores = clf.decision_scores_  # raw outlier scores\n\nX_test_pred = clf.predict(X_test_scaled)  # outlier labels (0 or 1)\nX_test_scores = clf.decision_function(X_test_scaled)  # outlier scores\n\nReplace prediction classes (0 & 1) with strings:\n\nlabels = {0: 'inlier', 1: 'outlier'}\n\nX_train_pred = np.vectorize(labels.get)(X_train_pred)\nX_test_pred = np.vectorize(labels.get)(X_test_pred)\n\nVisualize with T-SNE:\n\npx.scatter(x=X_train_viz[:,0], y=X_train_viz[:,1], title=\"Train set\", color=X_train_pred)\n\n\n                                                \n\n\n\npx.scatter(x=X_test_viz[:,0], y=X_test_viz[:,1], title=\"Test set\",  color=X_test_pred)\n\n\n                                                \n\n\nFull source code: https://github.com/mrtkp9993/MyDsProjects/tree/main/AnomalyOcsvm\n\n\nReferences\n\\(^1\\) http://odds.cs.stonybrook.edu/seismic-dataset/\n\\(^2\\) Saket Sathe and Charu C. Aggarwal. LODES: Local Density meets Spectral Outlier Detection. SIAM Conference on Data Mining, 2016.\n\\(^3\\) https://scikit-learn.org/stable/modules/outlier_detection.html\n\\(^4\\) Contributors to Wikimedia projects. (2022, September 03). Anomaly detection - Wikipedia. Retrieved from https://en.wikipedia.org/w/index.php?title=Anomaly_detection&oldid=1108262189\n\\(^5\\) Yengi, Yeliz & Kavak, Adnan & Arslan, Huseyin. (2020). Physical Layer Detection of Malicious Relays in LTE-A Network Using Unsupervised Learning. IEEE Access. PP. 1-1. 10.1109/ACCESS.2020.3017045.\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "ConceptDrift/Analysis.html",
    "href": "ConceptDrift/Analysis.html",
    "title": "Model Drift",
    "section": "",
    "text": "Model drift is a huge problem for machine learning models in production. Model drift reveals itself as a significant increase in error rates for models. To reduce risk, it is essential to track model performance and detect concept drift.\nAssume that, given a set of features \\(X\\) and a target variable \\(y\\), we are trying to predict the target variable. Then, model drift can occur as following:\n\nIf \\(P(y|X)\\) conditional distribution changes over time, this is called concept drift;\nif \\(P(y)\\) distribution changes over time, this is called label drift;\nif \\(P(X)\\) distribution changes over time, this is called data drift.\n\nWe’ve said that “changes over time”, this change can occur at different shapes:\n\nSudden drift: Change occurs in a short period of time.\nGradual drift: Change occurs gradually.\nIncremental drift: Change occurs incrementally.\nReoccurring drifts: Some time after a change occurs, the old distribution comes again."
  },
  {
    "objectID": "ConceptDrift/Analysis.html#kolmogorov-smirnov-ks-test-chi-squared-test",
    "href": "ConceptDrift/Analysis.html#kolmogorov-smirnov-ks-test-chi-squared-test",
    "title": "Model Drift",
    "section": "Kolmogorov-Smirnov (KS) Test & Chi-squared Test",
    "text": "Kolmogorov-Smirnov (KS) Test & Chi-squared Test\nThese sets used for compare two statistical distributions. We can apply these tests to compare distributions of training data and post-training data."
  },
  {
    "objectID": "ConceptDrift/Analysis.html#population-stability-index-psi",
    "href": "ConceptDrift/Analysis.html#population-stability-index-psi",
    "title": "Model Drift",
    "section": "Population Stability Index (PSI)",
    "text": "Population Stability Index (PSI)\nPSI is a measure for determining how much a population shifted over time."
  },
  {
    "objectID": "ConceptDrift/Analysis.html#drift-detection-method-early-drift-detection-method",
    "href": "ConceptDrift/Analysis.html#drift-detection-method-early-drift-detection-method",
    "title": "Model Drift",
    "section": "Drift Detection Method / Early Drift Detection Method",
    "text": "Drift Detection Method / Early Drift Detection Method\n\nDrift Detection Method (DDM) uses a binomial distribution to describe the behavior of a random variable that gives the number of classification errors. If the distribution of the samples is stationary, probability of misclassification will decrease as sample size increases. If the error rate of the learning algorithm increases significantly, it suggests changes in the distribution of classes, and thus providing the signal to update the model \\(^5\\).\n\n\nEarly Drift Detection Method (EDDM) is a modification of DDM and improves the detection in presence of gradual concept drift \\(^5\\)."
  },
  {
    "objectID": "ConceptDrift/Analysis.html#page-hinkley-method",
    "href": "ConceptDrift/Analysis.html#page-hinkley-method",
    "title": "Model Drift",
    "section": "Page-Hinkley method",
    "text": "Page-Hinkley method\n\nThis change detection method works by computing the observed values and their mean up to the current moment \\(^6\\)."
  },
  {
    "objectID": "ConceptDrift/Analysis.html#adwin",
    "href": "ConceptDrift/Analysis.html#adwin",
    "title": "Model Drift",
    "section": "ADWIN",
    "text": "ADWIN\n\nADWIN (ADaptive WINdowing) is a popular drift detection method with mathematical guarantees. ADWIN efficiently keeps a variable-length window of recent items; such that it holds that there has no been change in the data distribution. This window is further divided into two sub-windows \\((W_0, W_1)\\) used to determine if a change has happened. ADWIN compares the average of \\(W_0\\) and \\(W_1\\) to confirm that they correspond to the same distribution. Concept drift is detected if the distribution equality no longer holds. Upon detecting a drift, \\(W_0\\) is replaced by \\(W_1\\) and a new \\(W_0\\) is initialized. ADWIN uses a significance value \\(\\delta\\in(0,1)\\) to determine if the two sub-windows correspond to the same distribution \\(^8\\)."
  },
  {
    "objectID": "ConceptDrift/Analysis.html#solutions-to-model-drift",
    "href": "ConceptDrift/Analysis.html#solutions-to-model-drift",
    "title": "Model Drift",
    "section": "Solutions to model drift",
    "text": "Solutions to model drift\n\nDiscard the old data and retrain the model blindly without detecting any concept drift periodically.\nWeight the all data inversly propotional to the age of data, then train the model.\nUse online (incremental) learning. As the new data arrives, retrain the existing model.\n\nFull source code: https://github.com/mrtkp9993/MyDsProjects/tree/main/ConceptDrift"
  },
  {
    "objectID": "EarthQuakeProbability/Analysis.html#time-span-between-earthquake-occurrences",
    "href": "EarthQuakeProbability/Analysis.html#time-span-between-earthquake-occurrences",
    "title": "Modelling the probability of earthquakes (M >= 5.0) in North Anatolian Fault Zone",
    "section": "Time Span between Earthquake Occurrences",
    "text": "Time Span between Earthquake Occurrences\n\n```{r}\np <- ggplot(data_diff_between_eq, aes(x=diff)) + geom_histogram(aes(y = ..density..)) + geom_density()\np\n```\n\n\n\n\n\n```{r}\np2 <- ggplot(data_diff_between_eq, aes(x=diff)) + geom_boxplot()\np2\n```"
  },
  {
    "objectID": "EarthQuakeProbability/Analysis.html#earthquake-count-by-year",
    "href": "EarthQuakeProbability/Analysis.html#earthquake-count-by-year",
    "title": "Modelling the probability of earthquakes (M >= 5.0) in North Anatolian Fault Zone",
    "section": "Earthquake Count By Year",
    "text": "Earthquake Count By Year\n\n```{r}\np3 <- ggplot(data_count_by_year, aes(x=year, y=count)) + geom_line()\np3\n```"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Data Science Blog & Projects",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nTime Series Classification with Random Forests\n\n\n\nSep 17, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUncertainty Quantification with Polynomial Chaos\n\n\n\nSep 13, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnsupervised Anomaly Detection with One-Class SVM\n\n\n\nSep 10, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNonlinear System Identification with NARMAX\n\n\n\nSep 7, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel Drift\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDon’t Try to Forecast Everything: Predictability of Time Series\n\n\n\nSep 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDon’t impute all missing data: Missing Data Patterns\n\n\n\nAug 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStock Return and Fundamental Clustering & Portfolio Selection\n\n\n\nAug 26, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelling the probability of earthquakes (M >= 5.0) in North Anatolian Fault Zone\n\n\n\nAug 25, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "MissingData/Analysis.html",
    "href": "MissingData/Analysis.html",
    "title": "Don’t impute all missing data: Missing Data Patterns",
    "section": "",
    "text": "A missing data pattern is the structure of observed and missing values in a data set. This is not to be confused with a missing data mechanism, which describes possible relationships between data and an one’s propensity for missing values. Patterns describe where the gaps in the data are, whereas mechanisms explain why the values are missing.\n\nThe missing values in panel a have been isolated on a single variable in the univariate pattern. This pattern could appear, for example, in an experimental setting where outcome scores for a subset of participants are missing. Panel b depicts a monotone missing data pattern from a longitudinal study in which individuals who have missing data at one measurement event always have missing data at subsequent measurements. The general pattern in panel c is that missing values are scattered all through the entire data matrix. Panel d depicts a planned missing data pattern in which three variables are intentionally left blank for a large number of respondents. Panel e depicts a pattern in which a latent variable is absent across the entire sample.\nOne final configuration needs special consideration because it may introduce estimation issues for modern missing data-handling procedures. Because the data provide insufficient support for estimation, I refer to the configuration in panel f as an underidentified missing pattern. This pattern frequently occurs when two categorical variables have unbalanced group sizes and missing data, resulting in very low or even zero cell counts in a cross-tabulation table. Prior to conducting a missing data analysis, it is critical to screen for this configuration."
  },
  {
    "objectID": "MissingData/Analysis.html#distinguish-between-mnar-and-mar",
    "href": "MissingData/Analysis.html#distinguish-between-mnar-and-mar",
    "title": "Don’t impute all missing data: Missing Data Patterns",
    "section": "Distinguish between MNAR and MAR",
    "text": "Distinguish between MNAR and MAR\nThere is no statistical test for this, but you can:\n\nUse domain knowledge about variables;\nCollect more data for explaning missingness;\nDo literature search\n\nfor determining the missing data mechanisim."
  },
  {
    "objectID": "MissingData/Analysis.html#distinguish-between-mcar-and-mar",
    "href": "MissingData/Analysis.html#distinguish-between-mcar-and-mar",
    "title": "Don’t impute all missing data: Missing Data Patterns",
    "section": "Distinguish between MCAR and MAR",
    "text": "Distinguish between MCAR and MAR\nGenerally, two methods are preferred:\n\nLittle’s MCAR test: Maximum likelihood chi-square test for missing completely at random. \\(H_0\\) is that the data is MCAR.\nDummy variable approach for MCAR: One can create a dummy variable for whether a variable is missing (1 = missing, 0 = observed) and run t-tests (continuous) and chi-square (categorical) tests between this dummy and other variables to see if the missingness is related to the values of other variables."
  },
  {
    "objectID": "StockClustering/Analysis.html",
    "href": "StockClustering/Analysis.html",
    "title": "Stock Return and Fundamental Clustering & Portfolio Selection",
    "section": "",
    "text": "Introduction\nWe have following features for BIST30 stocks:\n\nMomentum 3-months, 6-months, 1-year\nVolatility 1-year, 2-year, 3-year\nPrice-To-Book Ratio\nMarket Capitalization\nReturn On Equity\nEarnings Growth\n\n\n\n\n\n  \n\n\n\nWe need to standardize the features:\n\n```{r}\nlibrary(scales)\n\ncols <- 5:ncol(data)\n\ndata_scaled <- lapply(data[, cols], function(x) if(is.numeric(x)) rescale(x, to=c(0,1)) else x)\ndata_scaled <- as.data.frame(data_scaled)\ndata_scaled <- cbind(data[,1:4], data_scaled)\ndata_scaled\n```\n\n\n\n  \n\n\n\nWe will use K-means method. Let’s plot elbow plot:\n\nWe have four clusters, let’s fit model and see results:\n\n\n\nClusters\nN\nR\\(^{2}\\)\nAIC\nBIC\nSilhouette\n\n\n\n\n\\(4\\)\n\\(30\\)\n\\(0.606\\)\n\\(194.190\\)\n\\(250.240\\)\n\\(0.310\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCluster\n\\(1\\)\n\\(2\\)\n\\(3\\)\n\\(4\\)\n\n\n\n\nSize\n\\(17\\)\n\\(2\\)\n\\(9\\)\n\\(2\\)\n\n\nExplained proportion within-cluster heterogeneity\n\\(0.616\\)\n\\(0.127\\)\n\\(0.192\\)\n\\(0.065\\)\n\n\nWithin sum of squares\n\\(70.320\\)\n\\(14.532\\)\n\\(21.962\\)\n\\(7.376\\)\n\n\nSilhouette score\n\\(0.267\\)\n\\(0.029\\)\n\\(0.419\\)\n\\(0.449\\)\n\n\n\n\n\n\n\nValue\n\n\n\n\nMaximum diameter\n\\(5.696\\)\n\n\nMinimum separation\n\\(1.664\\)\n\n\nPearson’s γ\n\\(0.593\\)\n\n\nDunn index\n\\(0.292\\)\n\n\nEntropy\n\\(1.044\\)\n\n\nCalinski-Harabasz index\n\\(13.343\\)\n\n\n\nThere is no negative silhouette score, but second cluster’s score is near to zero. It indicates that seperetion is not well.\nCluster contents:\n\n\n\n\n  \n\n\n\nLet’s look the mean return statistics of each cluster:\n\n\n\n\n  \n\n\n\nMean returns will be better if we select stocks from a bigger stock set like BIST100 or all BIST stocks.\nFull source code: https://github.com/mrtkp9993/MyDsProjects/tree/main/StockClustering\n\n\nReferences\n\\(^1\\) https://www.investopedia.com/terms/c/cluster_analysis.asp\n\\(^2\\) https://www.investopedia.com/terms/f/factor-investing.asp\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "SysIdent/Analysis.html",
    "href": "SysIdent/Analysis.html",
    "title": "Nonlinear System Identification with NARMAX",
    "section": "",
    "text": "System identification is a way to determine a system’s mathematical description by analyzing the system’s observed inputs and outputs. Definitely, the dynamics of the mathematical model that produced this signal from the measured input are hidden inside the output signal; how can this information be extracted? System identification provides a solution to this problem. Even under ideal conditions, this is difficult because the model of the system will be unknown, such as whether it is linear or nonlinear, how many terms are in the model, what type of terms should be in the model, whether the system has a time delay, what type of nonlinearity describes this system, and so on. Yet, if system is to be useful, these problems must be resolved. The benefits of system identification are numerous: it is applicable to all systems, it is frequently fast, and it can be used to track changes in the system\\(^1\\).\nWhat do we mean with “system”? One can think of “system” as any set of mathematical operations that takes one or more inputs and produces one or more outputs. Anything that can be related to input and output data is a system example: electrical systems, mechanical systems, biological systems, financial systems, chemical systems…\\(^3\\)\n\n\n\nSource: \\(^2\\)\n\n\nSystems can be considered of two types, depending on whether they satisfy the principle of superposition:\n\nLinear systems are satisfies the superposition principle: if system is linear, then if input \\(X_1\\) generates response \\(Y_1\\) and input \\(X_2\\) generates response \\(Y_2\\), then input \\(X_1 + X_2\\) generates response \\(Y_1 + Y_2\\).\nOn the other hand, nonlinear systems does not satisfy the superposition principle. This description is very vague, but there are so many types of nonlinear systems, it is almost impossible to write down a description that covers all the classes \\(^1\\).\n\nMost of real-world dynamical systems are nonlinear. In this article, we will not talk about linearization of nonlinear systems, as we will focus on the NARMAX method.\nFollowing steps are needed for NARMAX modelling \\(^3\\):\n\nCollecting data;\nChoice of mathematical representation;\nDetecting model structure;\nParameter estimation;\nModel validation;\nAnalysis of model.\n\nNARMAX method was introduced in 1981 by Stephen A. Billings, NARMAX models are able to represent the most different and complex nonlinear systems. NARMAX models can be represented as:\n\\[\ny_k= F^\\ell[y_{k-1}, \\dotsc, y_{k-n_y},x_{k-d}, x_{k-d-1}, \\dotsc, x_{k-d-n_u}, e_{k-1}, \\dotsc, e_{k-n_e}] + e_k\n\\]\nwhere \\(n_y\\in \\mathbb{N}\\), \\(n_u \\in \\mathbb{N}\\) and \\(n_e \\in \\mathbb{N}\\) are the maximum lags for the system output and system input and system noise , respectively; \\(x_k \\in \\mathbb{R}^{n_x}\\) is the system input and \\(y_k \\in \\mathbb{R}^{n_y}\\) is the system output at discrete time \\(k \\in \\mathbb{N}^n\\); \\(d\\) is the time delay; \\(e_k \\in \\mathbb{R}^{n_e}\\) is system uncertainty and noise at discrete time \\(k\\), (source: \\(^3\\)).\nTo approximate the unknown mapping \\(f[\\cdot]\\), we can use several nonlinear functions like \\(^1\\):\n\nPolynomial basis: Polynomial NARMAX model can be written as\n\\[\n\\begin{aligned}\ny(k)=\\theta_0 &+\\sum_{i_i=1}^n f_{i_1}\\left(x_{i_1}(k)\\right)+\\sum_{i_1=1}^n \\sum_{i_2=i_1}^n f_{i_1 i_2}\\left(x_{i_1}(k), x_{i_2}(k)\\right)+\\cdots \\\\\n&+\\sum_{i_1=1}^n \\cdots \\sum_{i_{\\ell}=i_{l-1}}^n f_{i_1 i_2 \\cdots i_l}\\left(x_{i_1}(k), x_{i_2}(k), \\ldots, x_{i_{\\ell}}(k)\\right)+e(k)\n\\end{aligned},\n\\]\n\\[\nf_{i_1 i_2 \\cdots i_m}\\left(x_{i_1}(k), x_{i_2}(k), \\ldots, x_{i_m}(k)\\right)=\\theta_{i_1 i_2 \\cdots i_m} \\prod_{k=1}^m x_{i_k}(k), 1 \\leq m \\leq \\ell,\n\\]\n\\[\nx_m(k)= \\begin{cases}y(k-m) & 1 \\leq m \\leq n_y \\\\ u\\left(k-\\left(m-n_y\\right)\\right) & n_y+1 \\leq m \\leq n_y+n_u \\\\ e\\left(k-\\left(m-n_y-n_u\\right)\\right) & n_y+n_u+1 \\leq m \\leq n_y+n_u+n_e\\end{cases}\n\\]\nwhere \\(l\\) is the degree of polynomial nonlinearity, \\(\\theta_{i_1,i_2,\\ldots,i_m}\\) are model parameters, and \\(n=n_y+n_u+n_e\\), (source: \\(^1\\)).\nGeneralized additive models:\nGeneralized additive models are defined as:\n\\[\ny(k)=a_0+a_1y(k-1)+\\cdots+a_{n_y}y(k-n_y)+b_1u(k-1)+\\cdots+b_{n_u}u(k-n_u)+e(k)\n\\]\nwhere \\(y(k)\\), \\(u(k)\\), \\(e(k)\\), \\(n_y\\), \\(n_u\\) and \\(n_e\\) are defined as before.\nNeural networks:\nRecurrent NARX can be defined as:\n\\[\ny(k)=F[\\mathbf{x}(k)]=w_0+\\sum_{i=1}^m w_i \\phi_i(\\mathbf{x}(k))+e(k)\n\\]\nwhere \\(\\phi_i(\\cdot)\\) is the nonlinear activation function.\nRadial basis functions:\nRBF networks can be defined as:\n\\[\ny(k)=F[\\mathbf{x}(k)]=\\sum_{i=1}^N w_i \\phi(\\|\\mathbf{x}(k)-\\mathbf{x}(i)\\|)\n\\]\nwhere \\(\\mathbf{x}(k)=[x_1(k),\\ldots,x_n(k)]^T\\) is the \\(k\\)th observation vector (\\(k=1,2,\\ldots,N\\)), \\(\\phi(||\\mathbf{x}(k)-\\mathbf{x}(i)||\\) are some arbitrary nonlinear functions known as radial basis functions or kernels, and \\(W_i\\) are the unknown weights.\nWavelet basis:\nWavelet NARMAX model can be defined as:\n\\[\ny(k)=F^{(P)}[\\mathbf{x}(k)]+F^{(W)}[\\mathbf{x}(k)]+F^{(Z)}[\\mathbf{z}(k)]+e(k)\n\\]\nwhere \\(F^{(P)}[\\mathbf{x}(k)]\\) is polynomial model that is used to model any slow or smooth varying trends, F^{(W)}[(k)] is a wavelet model that is used to model rapid changes or nonsmooth dynamics, and F^{(Z)}[(k)] is a linear or nonlinear moving average model that models the noise:\n\\[\nF^{(W)}[\\mathbf{x}(k)] = c_0+F_1[\\mathbf{x}(k)]+F_2[\\mathbf{x}(k)]+\\cdots+F_n[\\mathbf{x}(k)]\n\\]\n\\[\n\\begin{gathered}\nF_1(\\mathbf{x}(k))=\\sum_{i=1}^n f_i\\left(x_i(k)\\right) \\\\\nF_2(\\mathbf{x}(k))=\\sum_{i=1}^n \\sum_{j=i+1}^n f_{i j}\\left(x_i(k), x_j(k)\\right) \\\\\nF_m(\\mathbf{x}(k))=\\sum_{1 \\leq i_1<i_2<\\cdots<i_m \\leq n} f_{i_1 i_2 \\cdots i_m}\\left(x_{i_1}(k), x_{i_2}(k), \\ldots, x_{i_m}(k)\\right), 2<m<n \\\\\nF_n(\\mathbf{x}(k))=f_{12 \\cdots n}\\left(x_1(k), x_2(k), \\ldots, x_n(k)\\right)\n\\end{gathered}\n\\]\nwhere \\(c_0\\) is constant and \\(F_i[\\cdot]\\) are individual wavelet sub-models."
  },
  {
    "objectID": "SysIdent/Analysis.html#lorenz-system",
    "href": "SysIdent/Analysis.html#lorenz-system",
    "title": "Nonlinear System Identification with NARMAX",
    "section": "Lorenz system",
    "text": "Lorenz system\nThe Lorenz system is a system of ordinary differential equations defined as:\n\\[\n\\begin{align*}\n\\frac{dx}{dt} &= \\sigma(y-x) \\\\\n\\frac{dy}{dt} &= x(\\rho-z)-y\\\\\n\\frac{dz}{dt} &= xy - \\beta z\n\\end{align*}\n\\] where \\(\\sigma, \\rho, \\beta\\) are model parameters.\nLet’s simulate the data with \\(\\rho=28, \\sigma=10, \\beta=8/3\\). Here is the time step \\(dt\\) is \\(0.01\\), final time \\(10\\), initial values \\((x_0,y_0,z_0)\\) is \\((0.1, 0.1, 0.1)\\):\n\nrho = 28\nsigma = 10\nbeta = 8/3\ndt = 0.01 \nT = 10\nn = int(T / dt) \nt = np.linspace(0, T, n)\n\nx = np.zeros(n)\ny = np.zeros(n)\nz = np.zeros(n)\n\nx[0] = 0.1\ny[0] = 0.1\nz[0] = 0.1\n\nfor i in range(n - 1):\n    x[i + 1] = x[i] + dt * (sigma * (y[i] - x[i]))\n    y[i + 1] = y[i] + dt * (x[i] * (rho - z[i]) - y[i])\n    z[i + 1] = z[i] + dt * (x[i] * y[i] - beta * z[i] )\n    \nfig, ax = plt.subplots(3, 1)\nax[0].plot(t, x, lw=2)\nax[1].plot(t, y, lw=2)\nax[2].plot(t, z, lw=2)\n\nax[0].set_title(\"x\", loc=\"right\")\nax[1].set_title(\"y\", loc=\"right\")\nax[2].set_title(\"z\", loc=\"right\")\n\nText(1.0, 1.0, 'z')\n\n\n\n\n\n\npx.line_3d(x=z,y=y,z=x, title=\"Lorenz system\") # xz axis inverted for sake of plot\n\n\n                                                \n\n\nDivide data to train and validation sets, last 50 observations will be validation set:\n\ntest_size = 50\n\nx_train, x_valid = temporal_train_test_split(pd.Series(x), test_size=test_size)\ny_train, y_valid = temporal_train_test_split(pd.Series(y), test_size=test_size)\nz_train, z_valid = temporal_train_test_split(pd.Series(z), test_size=test_size)\n\nplot_series(x_train, x_valid, labels=[\"x_train\", \"x_valid\"])\nplot_series(y_train, y_valid, labels=[\"y_train\", \"y_valid\"])\nplot_series(z_train, z_valid, labels=[\"z_train\", \"z_valid\"])\n\n(<Figure size 1152x288 with 1 Axes>, <AxesSubplot:>)\n\n\n\n\n\n\n\n\n\n\n\nComputations:\n\nfrom sysidentpy.model_structure_selection import FROLS\nfrom sysidentpy.basis_function._basis_function import Polynomial, Fourier\nfrom sysidentpy.utils.display_results import results\nfrom sysidentpy.utils.plotting import plot_residues_correlation, plot_results\nfrom sysidentpy.residues.residues_correlation import compute_residues_autocorrelation, compute_cross_correlation\n\n# Reshape data (needed for sysidentpy)\nx_train = x_train.values.reshape(-1, 1)\nx_valid = x_valid.values.reshape(-1, 1)\ny_train = y_train.values.reshape(-1, 1)\ny_valid = y_valid.values.reshape(-1, 1)\nz_train = z_train.values.reshape(-1, 1)\nz_valid = z_valid.values.reshape(-1, 1)\n\n# Our polynomial basis functions with max degrees 5\nbasis_function = Polynomial(degree=5) \n\n# Forward Regression with Orthogonal Least Squares (FOLRS) model structure identification\nmodelx = FROLS(\n    order_selection=True,\n    ylag=4,\n    elag=4,\n    info_criteria='aic',\n    estimator='recursive_least_squares',\n    basis_function=basis_function,\n    model_type='NAR' # we don't have exogenous variables\n)\n\n# Fit model to training data\nmodelx.fit(y=x_train)\n\n# Add needed lags to validation data\nx_valid = np.concatenate([x_train[-modelx.max_lag:], x_valid])\n\n# Predict the validation data\nxhat = modelx.predict(y=x_valid, forecast_horizon=test_size)\n\nCalculate MSE error score:\n\nfrom sktime.performance_metrics.forecasting import mean_squared_error\n\nmodelx_loss = mean_squared_error(x_valid, xhat)\nprint(modelx_loss)\n\n0.0033133566986800886\n\n\nRegression coefficients:\n\nr = pd.DataFrame(\n    results(\n        modelx.final_model, modelx.theta, modelx.err,\n        modelx.n_terms, err_precision=8, dtype='sci'\n        ),\n    columns=['Regressors', 'Parameters', 'ERR'])\nprint(r)\n\n           Regressors   Parameters             ERR\n0              y(k-1)   3.7758E+00  9.95972552E-01\n1              y(k-2)  -5.3235E+00  3.97965581E-03\n2              y(k-3)   3.3225E+00  4.63994821E-05\n3              y(k-4)  -7.7480E-01  1.31535686E-06\n4            y(k-1)^3  -1.3230E-05  1.32545331E-08\n5      y(k-3)^2y(k-2)   3.5535E-04  6.13642972E-08\n6            y(k-4)^5   9.6040E-09  6.44836942E-10\n7  y(k-4)y(k-3)y(k-1)   4.3154E-04  2.56203519E-10\n8      y(k-4)y(k-2)^2  -7.7419E-04  8.56524112E-10\n\n\nPlot prediction results:\n\nplot_results(y=x_valid[modelx.max_lag:], yhat=xhat[modelx.max_lag:])\n\n\n\n\nWe’ve a perfect fit.\nResidual autocorrelation and cross-correlations:\n\nee = compute_residues_autocorrelation(x_valid, xhat)\nplot_residues_correlation(data=ee, title=\"Residues\", ylabel=\"$e^2$\")\nx1e = compute_cross_correlation(x_valid, xhat, x_valid)\nplot_residues_correlation(data=x1e, title=\"Residues\", ylabel=\"$x_1e$\")\n\n\n\n\n\n\n\n\\(y\\) and \\(z\\) components of the Lorenz model also can be estimated above. Now, let’s add measurement noise to our data and try to estimate it."
  },
  {
    "objectID": "SysIdent/Analysis.html#noisy-lorenz-system",
    "href": "SysIdent/Analysis.html#noisy-lorenz-system",
    "title": "Nonlinear System Identification with NARMAX",
    "section": "Noisy Lorenz System",
    "text": "Noisy Lorenz System\nNow we will assume that we observed the data with independent and identically distributed measurement noise (we will assume that measurement noise is distributed as uniform on interval [-1, 1]):\n\\[\n\\text{Observed Data} = \\text{Process Outcome} + \\text{Measurement Noise}\n\\]\nSimulate the noisy Lorenz system:\n\n# ...\n# add measurement noise to observations\nx = x + np.random.uniform(-1,1,n)\ny = y + np.random.uniform(-1,1,n)\nz = z + np.random.uniform(-1,1,n)\n\n\nfig, ax = plt.subplots(3, 1)\nax[0].plot(t, x, lw=2)\nax[1].plot(t, y, lw=2)\nax[2].plot(t, z, lw=2)\n\nax[0].set_title(\"x\", loc=\"right\")\nax[1].set_title(\"y\", loc=\"right\")\nax[2].set_title(\"z\", loc=\"right\")\n\npx.line_3d(x=z,y=y,z=x, title=\"Noisy Lorenz system\")\n\n\n                                                \n\n\n\n\n\nNow apply same method and look results:\nLoss:\n\nmodelx_loss = mean_squared_error(x_valid, xhat)\nprint(modelx_loss)\n\n3.1303289624476904\n\n\nRegression coefficients:\n\nr = pd.DataFrame(\n    results(\n        modelx.final_model, modelx.theta, modelx.err,\n        modelx.n_terms, err_precision=8, dtype='sci'\n        ),\n    columns=['Regressors', 'Parameters', 'ERR'])\nprint(r)\n\n                Regressors   Parameters             ERR\n0                   y(k-1)   4.5142E-01  9.86393489E-01\n1          y(k-11)^2y(k-7)  -9.1477E-04  2.95518502E-03\n2                   y(k-2)   3.0778E-01  1.52411152E-03\n3        y(k-11)^3y(k-9)^2   1.4444E-06  5.72445300E-04\n4                   y(k-3)   3.6355E-01  3.32725057E-04\n5                   y(k-9)  -1.5725E-01  3.16618507E-04\n6  y(k-10)^2y(k-3)y(k-2)^2  -6.5121E-07  1.64874661E-04\n7                   y(k-4)   1.0455E-01  1.71874614E-04\n\n\nPlot prediction results:\n\nplot_results(y=x_valid[modelx.max_lag:], yhat=xhat[modelx.max_lag:])\n\n\n\n\nIn the presence of noise, we added more lagged variables to the model and we tried to approximate the nature of the process.\nResidual autocorrelation and cross-correlations:\n\nee = compute_residues_autocorrelation(x_valid, xhat)\nplot_residues_correlation(data=ee, title=\"Residues\", ylabel=\"$e^2$\")\nx1e = compute_cross_correlation(x_valid, xhat, x_valid)\nplot_residues_correlation(data=x1e, title=\"Residues\", ylabel=\"$x_1e$\")\n\n\n\n\n\n\n\nFull source code: https://github.com/mrtkp9993/MyDsProjects/tree/main/SysIdent"
  },
  {
    "objectID": "TimeSeriesClassification/Analysis.html",
    "href": "TimeSeriesClassification/Analysis.html",
    "title": "Time Series Classification with Random Forests",
    "section": "",
    "text": "First, let’s look the methodology behind the idea.\nSuppose that \\(N\\) training time series examples \\(\\{e_1,e_2,\\ldots,e_N\\}\\) and the corresponding class labels \\(\\{y_1,\\ldots,y_N\\},\\quad y_i\\in\\{1,2,\\ldots,C\\}\\) where \\(C\\) is the class count, are given. The task is to predict the class labels for test examples. Here, for simplicity, we assume the values of time series are measured at equally-spaced intervals and training and test time series examples are of the same length \\(M\\) \\(^1\\).\n\n\n\nSource: https://www.sciencedirect.com/science/article/pii/B9780128119686000097\n\n\nTime series classification methods can be divided into two categories: Instance-based and feature-based. Instance-based methods like nearest-neighbor classifiers with Euclidean distance (NNEuclidean) or dynamic time warping (NNDTW) try to classify test examples based on its similarity to the training examples \\(^1\\).\nFeature-based methods build models on temporal features like \\(^3\\):\n\nSingular Value Decomposition (SVD),\nDiscrete Fourier Transform (DFT),\nCoefficients of the decomposition into Chebysev Polynominals,\nDiscrete Wavelet Transform (DWT),\nPiecewise Linear Approximation,\nARMA coefficients,\nSymbolic representations like Symbolic Aggregate approXimation (SAX)."
  },
  {
    "objectID": "TimeSeriesClassification/Analysis.html#atrial-fibrillation",
    "href": "TimeSeriesClassification/Analysis.html#atrial-fibrillation",
    "title": "Time Series Classification with Random Forests",
    "section": "Atrial Fibrillation",
    "text": "Atrial Fibrillation\n\nThis is a physionet dataset of two-channel ECG recordings has been created from data used in the Computers in Cardiology Challenge 2004, an open competition with the goal of developing automated methods for predicting spontaneous termination of atrial fibrillation (AF). The raw instances were 5 second segments of atrial fibrillation, containing two ECG signals, each sampled at 128 samples per second. The Multivate data organises these channels such that each is one dimension. The class labels are: n, s and t. class n is described as a non termination artiral fibrilation(that is, it did not terminate for at least one hour after the original recording of the data). class s is described as an atrial fibrilation that self terminates at least one minuet after the recording process. class t is descirbed as terminating immediatly, that is within one second of the recording ending. PhysioNet Reference: Goldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh, Mark RG, Mietus JE, Moody GB, Peng CK, Stanley HE. PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals. Circulation 101(23):e215-e220 [Circulation Electronic Pages; (Link Here) 2000 (June 13). PMID: 10851218; doi: 10.1161/01.CIR.101.23.e215 Publication: Moody GB. Spontaneous Termination of Atrial Fibrillation: A Challenge from PhysioNet and Computers in Cardiology 2004. Computers in Cardiology 31:101-104 (2004) \\(^5\\).\n\nLet’s read dataset:\n\nX_tr, y_tr = load_from_tsfile_to_dataframe(\"data/AtrialFibrillation_TRAIN.ts\")\nX_ts, y_ts = load_from_tsfile_to_dataframe(\"data/AtrialFibrillation_TEST.ts\")\n\nTake a look:\n\nMarkdown(tabulate(\n  X_tr.head(1), \n  headers=X_tr.columns\n))\n\n\n\n\n\ndim_0\ndim_1\n\n\n\n\n0\n0 -0.34086\n0 0.14820\n\n\n\n1 -0.38038\n1 0.13338\n\n\n\n2 -0.34580\n2 0.10868\n\n\n\n3 -0.36556\n3 0.09386\n\n\n\n4 -0.34580\n4 0.07410\n\n\n\n…\n…\n\n\n\n635 -0.04446\n635 -0.03458\n\n\n\n636 -0.04940\n636 -0.05928\n\n\n\n637 -0.02964\n637 -0.06916\n\n\n\n638 -0.01976\n638 -0.06916\n\n\n\n639 0.00000\n639 -0.07410\n\n\n\nLength: 640, dtype: float64\nLength: 640, dtype: float64\n\n\n\n\n\n\nMarkdown(tabulate(\n  y_tr, \n  headers=\"Labels\"\n))\n\nL\n\nn n n n n s s s s s t t t t t\n\n\n\nfig, axes = plt.subplots(nrows=2, ncols=1)\n\nX_tr.iloc[0,0].plot(ax=axes[0])\nX_tr.iloc[0,1].plot(ax=axes[1])\n\nfig.tight_layout()\nfig.subplots_adjust(top=0.88)\nfig.suptitle(\"non termination artiral fibrilation\")\nplt.show()\n\n\n\n\n\nfig, axes = plt.subplots(nrows=2, ncols=1)\n\nX_tr.iloc[6,0].plot(ax=axes[0])\nX_tr.iloc[6,1].plot(ax=axes[1])\n\nfig.tight_layout()\nfig.subplots_adjust(top=0.88)\nfig.suptitle(\"an atrial fibrilation that self terminates\")\nplt.show()\n\n\n\n\n\nfig, axes = plt.subplots(nrows=2, ncols=1)\n\nX_tr.iloc[12,0].plot(ax=axes[0])\nX_tr.iloc[12,1].plot(ax=axes[1])\n\nfig.tight_layout()\nfig.subplots_adjust(top=0.88)\nfig.suptitle(\"terminating immediatly\")\nplt.show()\n\n\n\n\nOur data is multivariate. We’ll use ColumnConcatenator which concatenates each dimension and converts multivariate time series to univariate time series.\n\ncc = ColumnConcatenator()\nX_tr = cc.fit_transform(X_tr)\nX_ts = cc.fit_transform(X_ts)\n\nLet’s train classifier:\n\nclf = TimeSeriesForestClassifier(min_interval=200, n_estimators=10000, n_jobs=-1, random_state=1234)\nclf.fit(X_tr, y_tr)\n\nTimeSeriesForestClassifier(min_interval=200, n_estimators=10000, n_jobs=-1,\n                           random_state=1234)\n\n\nPredict test data and check accuracy:\n\ny_pr = clf.predict(X_ts)\nprint(classification_report(y_ts, y_pr))\n\n              precision    recall  f1-score   support\n\n           n       1.00      0.40      0.57         5\n           s       0.50      0.60      0.55         5\n           t       0.29      0.40      0.33         5\n\n    accuracy                           0.47        15\n   macro avg       0.60      0.47      0.48        15\nweighted avg       0.60      0.47      0.48        15\n\n\n\nVisualize confusion matrix:\n\ncm = confusion_matrix(y_ts, y_pr, labels=['n', 's', 't'])\nax = sn.heatmap(pd.DataFrame(cm), annot=True, square=True, cbar=False, fmt='g')\nplt.xlabel(\"Predicted\") \nplt.ylabel(\"Actual\") \nax.invert_yaxis()\nplt.show()\n\n\n\n\nFull source code: https://github.com/mrtkp9993/MyDsProjects/tree/main/TimeSeriesClassification"
  },
  {
    "objectID": "TimeSeriesPredictability/Analysis.html",
    "href": "TimeSeriesPredictability/Analysis.html",
    "title": "Don’t Try to Forecast Everything: Predictability of Time Series",
    "section": "",
    "text": "Most of time series analyses start with investigating series, autocorrelation and partial autocorrelation plots. Then one estimates different time series models (like ARIMA, GARCH, State-space models) and performs model checks.\nBut no one asks whether that series is predictable or not.\nWe’ll look at a few handy tools that give more information about our time series."
  },
  {
    "objectID": "TimeSeriesPredictability/Analysis.html#lyapunov-exponent",
    "href": "TimeSeriesPredictability/Analysis.html#lyapunov-exponent",
    "title": "Don’t Try to Forecast Everything: Predictability of Time Series",
    "section": "Lyapunov Exponent",
    "text": "Lyapunov Exponent\nLyapunov exponent of a dynamical system is a quantity that characterizes the rate of separation of infinitesimally close trajectories. Quantitatively, two trajectories in phase space with initial separation vector \\(\\delta Z_0\\) diverge at a rate given by\n\\[\n|\\delta Z(t)|\\approx e^{\\lambda t}|\\delta Z_0|\n\\]\nwhere \\(\\lambda\\) is the Lyapunov exponent. The rate of separation can be different for different orientations of initial separation vector. Thus, there is a spectrum of Lyapunov exponents. It is common to refer to the largest one as the maximal Lyapunov exponent (MLE), because it determines a notion of predictability for a dynamical system \\(^{7}\\).\n\n\nI’ll not go into detail on how to calculate the maximal Lyapunov exponent, we’ll look at practical implications.\nA positive MLE is usually taken as an indication that the system is chaotic \\(^{7}\\)."
  },
  {
    "objectID": "TimeSeriesPredictability/Analysis.html#hurst-exponent",
    "href": "TimeSeriesPredictability/Analysis.html#hurst-exponent",
    "title": "Don’t Try to Forecast Everything: Predictability of Time Series",
    "section": "Hurst Exponent",
    "text": "Hurst Exponent\nThe Hurst exponent is referred to as the “index of dependence” or “index of long-range dependence”. It quantifies the relative tendency of a time series either to regress strongly to the mean or to cluster in a direction:\n\nTrending (Persistent) series: If \\(0.5 < H \\leq 1\\) , then series has long-term positive autocorrelation, so a high value in the series will probably be followed by another high value and the future will also tend to be high;\nRandom walk series: if \\(H = 0.5\\), then series is a completely uncorrelated series, so it can go either way (up or down);\nMean-reverting (Anti-persistent) series: if \\(0 \\leq H < 0.5\\), then series has mean-reversion, so a high value in the series will probably be followed by a low value and vice versa \\(^{8}\\)."
  },
  {
    "objectID": "TimeSeriesPredictability/Analysis.html#detrended-fluctuation-analysis",
    "href": "TimeSeriesPredictability/Analysis.html#detrended-fluctuation-analysis",
    "title": "Don’t Try to Forecast Everything: Predictability of Time Series",
    "section": "Detrended Fluctuation Analysis",
    "text": "Detrended Fluctuation Analysis\nDFA is a method for determining the statistical self-affinity of a signal. It is the generalization of Hurst exponent, it means \\(^{8}\\):\n\nfor \\(0<\\alpha<0.5\\), then the series is anti-correlated;\nfor \\(\\alpha=0.5\\), then the series is uncorrelated and corresponds to white noise;\nfor \\(0.5<\\alpha<1\\), then the series is correlated;\nfor \\(\\alpha\\approx1\\), then the series corresponds to pink noise;\nfor \\(\\alpha>1\\), then the series is nonstationary and unbounded;\nfor \\(\\alpha\\approx1.5\\), then the series corresponds to Brownian noise."
  },
  {
    "objectID": "TimeSeriesPredictability/Analysis.html#variance-ratio-test",
    "href": "TimeSeriesPredictability/Analysis.html#variance-ratio-test",
    "title": "Don’t Try to Forecast Everything: Predictability of Time Series",
    "section": "Variance Ratio Test",
    "text": "Variance Ratio Test\nThis test is often used to test the hypothesis that a given time series is a collection of i.i.d. observations or that it follows a martingale difference sequence.\nWe will use Chow and Denning’s multiple variance ratio test. There are two tests:\n\nCD1 - Test for i.i.d. series,\nCD2 - Test for uncorrelated series with possible heteroskedasticity.\n\nIf test statistics are bigger than critical values, the null hypothesis is rejected which means the series is not a random walk."
  },
  {
    "objectID": "TimeSeriesPredictability/Analysis.html#airpassengers-data",
    "href": "TimeSeriesPredictability/Analysis.html#airpassengers-data",
    "title": "Don’t Try to Forecast Everything: Predictability of Time Series",
    "section": "AirPassengers data",
    "text": "AirPassengers data\nResults:\n\nLyapunov exponent spectrum:\n\n\nCall:\nLyapunov exponent spectrum \n\nCoefficients:\n             Estimate Std. Error   z value      Pr(>|z|)\nExponent 1 -0.8398548  0.2333552 -28.33887 5.739062e-177\nExponent 2 -1.5136329  0.1937088 -61.52719  0.000000e+00\n---\nProcedure: QR decomposition by bootstrap blocking method \nEmbedding dimension: 2, Time-delay: 1, No. hidden units: 10\nSample size: 129, Block length: 62, No. blocks: 1000\n\n\nThere are two statistically significant exponent estimates. The largest one is -0.84 which is negative, which means the series is not chaotic.\nHurst exponent is 0.8206234; it is bigger than 0.5, so series is trending.\nDFA is estimated as 1.2988566; it is nonstationary and unbounded.\nVariance ratio test:\n\n\n$Holding.Periods\n[1]  2  4  5  8 10 27\n\n$CD1\n[1] 24.48521\n\n$CD2\n[1] 21.22941\n\n$Critical.Values_10_5_1_percent\n[1] 2.378000 2.631038 3.142756\n\n\nBoth of test statistics are bigger than critical values, so the series is not a random walk."
  },
  {
    "objectID": "TimeSeriesPredictability/Analysis.html#lakehuron-data",
    "href": "TimeSeriesPredictability/Analysis.html#lakehuron-data",
    "title": "Don’t Try to Forecast Everything: Predictability of Time Series",
    "section": "LakeHuron data",
    "text": "LakeHuron data\nResults:\n\nLyapunov exponent spectrum:\n\n\nCall:\nLyapunov exponent spectrum \n\nCoefficients:\n             Estimate Std. Error    z value Pr(>|z|)\nExponent 1 -0.2245224 0.03079226  -56.00722        0\nExponent 2 -0.6465142 0.01144893 -433.74968        0\nExponent 3 -0.6696687 0.01006248 -511.18811        0\nExponent 4 -1.6931702 0.02747627 -473.33519        0\n---\nProcedure: QR decomposition by bootstrap blocking method \nEmbedding dimension: 4, Time-delay: 1, No. hidden units: 2\nSample size: 94, Block length: 59, No. blocks: 1000\n\n\nThere are four statistically significant exponent estimates. The largest one is -0.22 which is negative, which means the series is not chaotic.\nHurst exponent is 0.7364948; it is bigger than 0.5, so series is trending.\nDFA is estimated as 1.1128455; it is nonstationary and unbounded.\nVariance ratio test:\n\n\n$Holding.Periods\n[1]  2  4  5  8 10  3\n\n$CD1\n[1] 11.45734\n\n$CD2\n[1] 9.407748\n\n$Critical.Values_10_5_1_percent\n[1] 2.378000 2.631038 3.142756\n\n\nBoth of test statistics are bigger than critical values, so the series is not a random walk."
  },
  {
    "objectID": "TimeSeriesPredictability/Analysis.html#simulated-time-series-data-from-the-logistic-map-with-chaos",
    "href": "TimeSeriesPredictability/Analysis.html#simulated-time-series-data-from-the-logistic-map-with-chaos",
    "title": "Don’t Try to Forecast Everything: Predictability of Time Series",
    "section": "Simulated time-series data from the Logistic map with chaos",
    "text": "Simulated time-series data from the Logistic map with chaos\nResults:\n\nLyapunov exponent spectrum:\n\n\nCall:\nLyapunov exponent spectrum \n\nCoefficients:\n            Estimate Std. Error   z value Pr(>|z|)\nExponent 1 -1.291195  0.1580609 -63.27662        0\n---\nProcedure: QR decomposition by bootstrap blocking method \nEmbedding dimension: 1, Time-delay: 1, No. hidden units: 2\nSample size: 99, Block length: 60, No. blocks: 1000\n\n\nThere is one statistically significant exponent estimate, -1.29 which is negative, which means the series is not chaotic which is a questionable result.\nHurst exponent is 0.6255664; it is bigger than 0.5, so series is trending.\nDFA is estimated as 0.758476; it is correlated.\nVariance ratio test:\n\n\n$Holding.Periods\n[1]  2  4  5  8 10 10\n\n$CD1\n[1] 1.193817\n\n$CD2\n[1] 1.295116\n\n$Critical.Values_10_5_1_percent\n[1] 2.378000 2.631038 3.142756\n\n\nBoth of test statistics are smaller than critical values, so the series is a random walk.\n\nFull source code: https://github.com/mrtkp9993/MyDsProjects/tree/main/TimeSeriesPredictability"
  },
  {
    "objectID": "UncertaintyQuantification/Analysis.html",
    "href": "UncertaintyQuantification/Analysis.html",
    "title": "Uncertainty Quantification with Polynomial Chaos",
    "section": "",
    "text": "Source: \\(^4\\)\n\n\nAccording to \\(^2\\), uncertainty quantification is defined as\n\nThe process of quantifying uncertainties associated with model calculations of true, physical QOIs, with the goals of accounting for all sources of uncertainty and quantifying the contributions of specific sources to the overall uncertainty.\n\nand answers the question\n\nHow do the various sources of error and uncertainty feed into uncertainty in the model-based prediction of the quantities of interest?"
  },
  {
    "objectID": "UncertaintyQuantification/Analysis.html#logistic-growth-model-example",
    "href": "UncertaintyQuantification/Analysis.html#logistic-growth-model-example",
    "title": "Uncertainty Quantification with Polynomial Chaos",
    "section": "Logistic Growth Model Example",
    "text": "Logistic Growth Model Example\nLogistic growth model is defined as\n\\[\n\\frac{dX}{dt}=rX(1-\\frac{X}{K})\n\\]\nwhere \\(r\\) is the growth rate and \\(K\\) is the population capacity (horizontal asymptote).\nLet’s define the model and visualize it for some parameters and the initial condition \\(X_0=50\\):\n\nt = numpy.linspace(0, 10, 100)\nx0 = 50\n\ndef logistic_model(x, t, r, K):\n    return r * x * (1 - x / K)\n  \nfig, axs = plt.subplots(2,2)\nfig.suptitle('Logistic model with different params')\n\naxs = axs.ravel()\n\nfor i, params in enumerate([(0.7, 60), (1.1, 60), (0.7, 300), (1.1, 300)]):\n  sol = odeint(logistic_model, x0, t, args=params)\n  axs[i].plot(t, sol[:, 0], 'b', label='x(t)')\n  axs[i].legend(loc='best')\n  axs[i].set_xlabel('t')\n  axs[i].set_ylabel('x')\n  axs[i].grid()\n  axs[i].plot()\n    \nplt.show()\n\n\n\n\nNow let’s assume that we have uncertainties over our parameters and assume that\n\\[\n\\begin{align*}\nr &\\sim \\text{Log-Normal}(1, 0.1)\\\\\nK &\\sim \\text{Uniform}(100, 200)\n\\end{align*}\n\\] Let’s define our joint distribution:\n\nrdist= chaospy.LogNormal(1, 0.1)\nKdist = chaospy.Uniform(100, 200)\njoint = chaospy.J(rdist, Kdist)\n\ngrid = numpy.mgrid[joint.lower[0]:joint.upper[0]+1, joint.lower[1]:joint.upper[1]+1]\ncontour = plt.contourf(grid[0], grid[1], joint.pdf(grid), 50)\nplt.scatter(*joint.sample(50, seed=1234))\nplt.xlim(joint.lower[0], joint.upper[0])\nplt.ylim(joint.lower[1], joint.upper[1])\nplt.show()\n\n\n\n\nGenerate expension, sample the joint distribution, evaluate model at these points and plot:\n\nexpansion = chaospy.generate_expansion(order=3, dist=joint)\n\n# and sample the joint distribution\nsamples = joint.sample(1000, rule=\"sobol\")\n\n# and evulate solver at these samples\nevaluations = numpy.array([odeint(logistic_model, x0, t, args=(sample[0], sample[1])) for sample in samples.T])\n\n# and plot\nplt.plot(t, evaluations[:,:,0].T, alpha=0.1)\nplt.show()\n\n\n\n\nCreate polynomial approximation:\n\napprox_solver = chaospy.fit_regression(expansion, samples, evaluations)\n\nCalculate mean and deviance and plot:\n\nexpected = chaospy.E(approx_solver, joint)\ndeviation = chaospy.Std(approx_solver, joint)\n\nplt.fill_between(t, expected[:,0]-2*deviation[:,0], expected[:,0]+2*deviation[:,0], alpha=0.4)\nplt.plot(t, expected[:,0])\nplt.show()\n\n\n\n\nFull source code: https://github.com/mrtkp9993/MyDsProjects/tree/main/UncertaintyQuantification"
  }
]